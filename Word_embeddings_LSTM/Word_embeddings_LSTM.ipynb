{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Word embeddings with LSTM \n",
    "\n",
    "This notebook is based on the programming assignment \"Emojify!\" of deeplearning.ai, course Sequence Models, week Natural Language Processing & Word Emeddings. The figures are also taken from that assignment.\n",
    "\n",
    "We are going to build an Emojifier using word embeddings. We will implement an LSTM model which inputs a sentence in the form of word embeddings and finds the most appropriate emoji to be used with this sentence. \n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "- Application of long short-term memory (LSTM) neural network in TensorFlow\n",
    "- Use of embeddings\n",
    "- Build a pretrained embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##  Introduction\n",
    "\n",
    "We have a tiny dataset (X, Y) where:\n",
    "- X contains 127 sentences (strings)\n",
    "- Y contains an integer label between 0 and 4 corresponding to an emoji for each sentence\n",
    "\n",
    "<img src=\"images/data_set.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> EMOJISET: a classification problem with 5 classes. A few examples of sentences are given here. </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Network architecture\n",
    "\n",
    "Here is the Emojifier we will implement:\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center> Emojifier: A 2-layer LSTM sequence classifier. </center></caption>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'never talk to me again'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am so impressed by your dedication to this project'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(X_train, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'so',\n",
       " 'impressed',\n",
       " 'by',\n",
       " 'your',\n",
       " 'dedication',\n",
       " 'to',\n",
       " 'this',\n",
       " 'project']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(X_train, key=len).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split()) #VMG: find the number of words in the sentence with maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again ðŸ˜ž\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(X_train[index], label_to_emoji(Y_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will use pretrained 50-dimensional GloVe embeddings. The following cell loads the `word_to_vec_map`, which contains all the vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of word_to_index 400000\n",
      "length of index_to_word 400000\n",
      "length of word_to_vec_map 400000\n"
     ]
    }
   ],
   "source": [
    "print('length of word_to_index',len(word_to_index))\n",
    "print('length of index_to_word',len(index_to_word))\n",
    "print('length of word_to_vec_map',len(word_to_vec_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- `word_to_index`: dictionary mapping from words to their indices in the vocabulary (400,001 words, with the valid indices ranging from 0 to 400,000)\n",
    "- `index_to_word`: dictionary mapping from indices to their corresponding words in the vocabulary\n",
    "- `word_to_vec_map`: dictionary mapping words to their GloVe vector representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of cucumber in the vocabulary is 113317\n",
      "the 289846th word in the vocabulary is potatos\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "index = 289846\n",
    "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
    "print(\"the\", str(index) + \"th word in the vocabulary is\", index_to_word[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.68224 , -0.31608 , -0.95201 ,  0.47108 ,  0.56571 ,  0.13151 ,\n",
       "        0.22457 ,  0.094995, -1.3237  , -0.51545 , -0.39337 ,  0.88488 ,\n",
       "        0.93826 ,  0.22931 ,  0.088624, -0.53908 ,  0.23396 ,  0.73245 ,\n",
       "       -0.019123, -0.26552 , -0.40433 , -1.5832  ,  1.1316  ,  0.4419  ,\n",
       "       -0.48218 ,  0.4828  ,  0.14938 ,  1.1245  ,  1.0159  , -0.50213 ,\n",
       "        0.83831 , -0.31303 ,  0.083242,  1.7161  ,  0.15024 ,  1.0324  ,\n",
       "       -1.5005  ,  0.62348 ,  0.54508 , -0.88484 ,  0.53279 , -0.085119,\n",
       "        0.02141 , -0.56629 ,  1.1463  ,  0.6464  ,  0.78318 , -0.067662,\n",
       "        0.22884 , -0.042453])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec_map['cucumber']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We convert an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "X -- array of sentences (strings), of shape (m, 1)\n",
    "\n",
    "word_to_index -- a dictionary containing the each word mapped to its index\n",
    "\n",
    "max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
    "    \n",
    "Returns:\n",
    "\n",
    "X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "\n",
    "    #The output shape should be such that it can be given to `Embedding()` (described in Figure 4). \n",
    "    \n",
    "    m = X.shape[0] # number of training examples\n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    \n",
    "    for i in range(m):  # loop over training examples\n",
    "        \n",
    "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
    "        sentence_words =X[i].lower().split()\n",
    "        \n",
    "        j = 0\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in sentence_words:\n",
    "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "            X_indices[i, j] = word_to_index[w]\n",
    "            j = j+1\n",
    "                \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size):\n",
    "    for start_i in range(0, len(x), batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        yield x[start_i:end_i], y[start_i:end_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_inputs():\n",
    "    \n",
    "    inputs_ = tf.placeholder(tf.int32,[None,None],name='inputs_')\n",
    "    labels_ = tf.placeholder(tf.int32,[None,None],name='labels_')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return inputs_, labels_, keep_prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_embedding_matrix(vocab_len,embedding_dim):\n",
    "    \n",
    "    # Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\n",
    "    emb_matrix = np.zeros((vocab_len,embedding_dim))\n",
    "    \n",
    "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "        \n",
    "    return emb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_embedding_layer(vocab_len,embedding_dim,inputs_):\n",
    "    \n",
    "    W = tf.Variable(tf.constant(0.0, shape=[vocab_len, embedding_dim]),\n",
    "                trainable=False, name=\"W\")\n",
    "\n",
    "    embedding_placeholder = tf.placeholder(tf.float32, [vocab_len, embedding_dim])\n",
    "    embedding_init = W.assign(embedding_placeholder)\n",
    "    embed = tf.nn.embedding_lookup(W,inputs_)\n",
    "    \n",
    "    return embed, embedding_init, embedding_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, lstm_layers, batch_size, keep_prob):\n",
    "    \n",
    "    # Your basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size) \n",
    "    \n",
    "    # Add dropout to the cell\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop for _ in range(lstm_layers)])\n",
    "    \n",
    "    # Getting an initial state of all zeros\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size):\n",
    "    \n",
    "    x = lstm_output[:, -1]\n",
    "    \n",
    "    # Connect the LSTM outputs to a softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        # Create the weight and bias variables here\n",
    "        softmax_w = tf.Variable(tf.truncated_normal([in_size, out_size]))\n",
    "        softmax_b = tf.Variable(tf.zeros(out_size))\n",
    "        # out_size should be 5 because we have 5 emojis, i.e. 5 classes\n",
    "    \n",
    "    logits = tf.add(tf.matmul(x,softmax_w),softmax_b)\n",
    "    \n",
    "    # Use softmax to get the probabilities for predicted characters\n",
    "    predictions = tf.nn.softmax(logits)\n",
    "    \n",
    "    return predictions, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_loss_and_accuracy(predictions, logits, targets, num_classes):\n",
    "        \n",
    "    y_one_hot = tf.one_hot(targets, depth=num_classes)\n",
    "    y_reshaped = tf.reshape(y_one_hot,[-1,num_classes])\n",
    "    \n",
    "    # Softmax cross entropy loss\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped))\n",
    "    \n",
    "    # accuracy version 1\n",
    "    # correct_pred = tf.equal(tf.argmax(predictions,1), tf.argmax(y_reshaped,1))\n",
    "    # accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        \n",
    "    # accuracy version 2    \n",
    "    acc, acc_op = tf.metrics.accuracy(labels=tf.argmax(y_reshaped, 1), \n",
    "                                  predictions=tf.argmax(logits,1))\n",
    "    \n",
    "    return loss, acc, acc_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate):\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class emoji_model:\n",
    "    \n",
    "    def __init__(self, num_classes, num_steps,\n",
    "                       lstm_size, lstm_layers, learning_rate):\n",
    "    \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs_, self.labels_, self.keep_prob = build_inputs()\n",
    "        \n",
    "        self.batch_size_var= tf.shape(self.inputs_)[0]\n",
    "        \n",
    "        # Build the LSTM cell\n",
    "        self.cell, self.initial_state = build_lstm(lstm_size, lstm_layers, self.batch_size_var, self.keep_prob)\n",
    "        \n",
    "        #build pretrained embedding matrix\n",
    "        self.emb_matrix = build_embedding_matrix(vocab_len,embedding_dim)\n",
    "        \n",
    "        #build embedding layer\n",
    "        self.embed, self.embedding_init, self.embedding_placeholder = build_embedding_layer(vocab_len,embedding_dim,self.inputs_)\n",
    "        \n",
    "        ### Run the data through the RNN layers\n",
    "               \n",
    "        # Run each sequence step through the RNN with tf.nn.dynamic_rnn \n",
    "        self.lstm_output, state = tf.nn.dynamic_rnn(self.cell, self.embed, initial_state=self.initial_state)\n",
    "        \n",
    "        self.final_state = state\n",
    "\n",
    "        # Get softmax predictions and logits\n",
    "        self.predictions, self.logits = build_output(self.lstm_output, lstm_size, num_classes)\n",
    "           \n",
    "        # Loss and optimizer\n",
    "        self.loss, self.acc, self.acc_op = build_loss_and_accuracy(self.predictions, self.logits, self.labels_, num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 128\n",
    "lstm_layers = 2\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "num_classes=5\n",
    "vocab_len = len(word_to_index)+1           \n",
    "embedding_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/150 Train loss (mean): 2.9738 Train accuracy (mean): 0.3048\n",
      "Epoch: 2/150 Train loss (mean): 1.6501 Train accuracy (mean): 0.3654\n",
      "Epoch: 3/150 Train loss (mean): 1.0088 Train accuracy (mean): 0.4193\n",
      "Epoch: 4/150 Train loss (mean): 1.0922 Train accuracy (mean): 0.4543\n",
      "Epoch: 5/150 Train loss (mean): 1.0441 Train accuracy (mean): 0.4840\n",
      "Epoch: 6/150 Train loss (mean): 0.6809 Train accuracy (mean): 0.5249\n",
      "Epoch: 7/150 Train loss (mean): 0.5031 Train accuracy (mean): 0.5553\n",
      "Epoch: 8/150 Train loss (mean): 0.3319 Train accuracy (mean): 0.5899\n",
      "Epoch: 9/150 Train loss (mean): 0.2832 Train accuracy (mean): 0.6225\n",
      "Epoch: 10/150 Train loss (mean): 0.2946 Train accuracy (mean): 0.6512\n",
      "Epoch: 11/150 Train loss (mean): 0.3049 Train accuracy (mean): 0.6764\n",
      "Epoch: 12/150 Train loss (mean): 0.5154 Train accuracy (mean): 0.6940\n",
      "Epoch: 13/150 Train loss (mean): 0.7670 Train accuracy (mean): 0.7056\n",
      "Epoch: 14/150 Train loss (mean): 0.5911 Train accuracy (mean): 0.7140\n",
      "Epoch: 15/150 Train loss (mean): 0.4625 Train accuracy (mean): 0.7193\n",
      "Epoch: 16/150 Train loss (mean): 0.2900 Train accuracy (mean): 0.7282\n",
      "Epoch: 17/150 Train loss (mean): 0.1963 Train accuracy (mean): 0.7384\n",
      "Epoch: 18/150 Train loss (mean): 0.1683 Train accuracy (mean): 0.7494\n",
      "Epoch: 19/150 Train loss (mean): 0.1049 Train accuracy (mean): 0.7610\n",
      "Epoch: 20/150 Train loss (mean): 0.1260 Train accuracy (mean): 0.7715\n",
      "Epoch: 21/150 Train loss (mean): 0.1602 Train accuracy (mean): 0.7799\n",
      "Epoch: 22/150 Train loss (mean): 0.1170 Train accuracy (mean): 0.7878\n",
      "Epoch: 23/150 Train loss (mean): 0.1742 Train accuracy (mean): 0.7934\n",
      "Epoch: 24/150 Train loss (mean): 0.1469 Train accuracy (mean): 0.7990\n",
      "Epoch: 25/150 Train loss (mean): 0.1132 Train accuracy (mean): 0.8059\n",
      "Epoch: 26/150 Train loss (mean): 0.0488 Train accuracy (mean): 0.8127\n",
      "Epoch: 27/150 Train loss (mean): 0.0369 Train accuracy (mean): 0.8189\n",
      "Epoch: 28/150 Train loss (mean): 0.0198 Train accuracy (mean): 0.8252\n",
      "Epoch: 29/150 Train loss (mean): 0.0206 Train accuracy (mean): 0.8310\n",
      "Epoch: 30/150 Train loss (mean): 0.0200 Train accuracy (mean): 0.8364\n",
      "Epoch: 31/150 Train loss (mean): 0.0437 Train accuracy (mean): 0.8411\n",
      "Epoch: 32/150 Train loss (mean): 0.6944 Train accuracy (mean): 0.8453\n",
      "Epoch: 33/150 Train loss (mean): 0.3381 Train accuracy (mean): 0.8473\n",
      "Epoch: 34/150 Train loss (mean): 0.3785 Train accuracy (mean): 0.8481\n",
      "Epoch: 35/150 Train loss (mean): 0.2397 Train accuracy (mean): 0.8498\n",
      "Epoch: 36/150 Train loss (mean): 0.5287 Train accuracy (mean): 0.8514\n",
      "Epoch: 37/150 Train loss (mean): 0.1768 Train accuracy (mean): 0.8531\n",
      "Epoch: 38/150 Train loss (mean): 0.1582 Train accuracy (mean): 0.8554\n",
      "Epoch: 39/150 Train loss (mean): 0.1124 Train accuracy (mean): 0.8578\n",
      "Epoch: 40/150 Train loss (mean): 0.1993 Train accuracy (mean): 0.8607\n",
      "Epoch: 41/150 Train loss (mean): 0.1827 Train accuracy (mean): 0.8632\n",
      "Epoch: 42/150 Train loss (mean): 0.0697 Train accuracy (mean): 0.8663\n",
      "Epoch: 43/150 Train loss (mean): 0.0860 Train accuracy (mean): 0.8684\n",
      "Epoch: 44/150 Train loss (mean): 0.0287 Train accuracy (mean): 0.8708\n",
      "Epoch: 45/150 Train loss (mean): 0.0309 Train accuracy (mean): 0.8735\n",
      "Epoch: 46/150 Train loss (mean): 0.0153 Train accuracy (mean): 0.8763\n",
      "Epoch: 47/150 Train loss (mean): 0.0049 Train accuracy (mean): 0.8789\n",
      "Epoch: 48/150 Train loss (mean): 0.0202 Train accuracy (mean): 0.8813\n",
      "Epoch: 49/150 Train loss (mean): 0.0745 Train accuracy (mean): 0.8834\n",
      "Epoch: 50/150 Train loss (mean): 0.1155 Train accuracy (mean): 0.8855\n",
      "Epoch: 51/150 Train loss (mean): 0.2715 Train accuracy (mean): 0.8870\n",
      "Epoch: 52/150 Train loss (mean): 0.5788 Train accuracy (mean): 0.8883\n",
      "Epoch: 53/150 Train loss (mean): 0.8332 Train accuracy (mean): 0.8884\n",
      "Epoch: 54/150 Train loss (mean): 0.2984 Train accuracy (mean): 0.8883\n",
      "Epoch: 55/150 Train loss (mean): 0.2814 Train accuracy (mean): 0.8879\n",
      "Epoch: 56/150 Train loss (mean): 0.0756 Train accuracy (mean): 0.8892\n",
      "Epoch: 57/150 Train loss (mean): 0.0647 Train accuracy (mean): 0.8905\n",
      "Epoch: 58/150 Train loss (mean): 0.0201 Train accuracy (mean): 0.8923\n",
      "Epoch: 59/150 Train loss (mean): 0.0092 Train accuracy (mean): 0.8941\n",
      "Epoch: 60/150 Train loss (mean): 0.0059 Train accuracy (mean): 0.8959\n",
      "Epoch: 61/150 Train loss (mean): 0.0036 Train accuracy (mean): 0.8976\n",
      "Epoch: 62/150 Train loss (mean): 0.0062 Train accuracy (mean): 0.8993\n",
      "Epoch: 63/150 Train loss (mean): 0.0044 Train accuracy (mean): 0.9009\n",
      "Epoch: 64/150 Train loss (mean): 0.0034 Train accuracy (mean): 0.9025\n",
      "Epoch: 65/150 Train loss (mean): 0.0019 Train accuracy (mean): 0.9040\n",
      "Epoch: 66/150 Train loss (mean): 0.0020 Train accuracy (mean): 0.9054\n",
      "Epoch: 67/150 Train loss (mean): 0.0022 Train accuracy (mean): 0.9068\n",
      "Epoch: 68/150 Train loss (mean): 0.0040 Train accuracy (mean): 0.9082\n",
      "Epoch: 69/150 Train loss (mean): 0.0096 Train accuracy (mean): 0.9096\n",
      "Epoch: 70/150 Train loss (mean): 0.0013 Train accuracy (mean): 0.9109\n",
      "Epoch: 71/150 Train loss (mean): 0.0021 Train accuracy (mean): 0.9121\n",
      "Epoch: 72/150 Train loss (mean): 0.0014 Train accuracy (mean): 0.9133\n",
      "Epoch: 73/150 Train loss (mean): 0.0004 Train accuracy (mean): 0.9145\n",
      "Epoch: 74/150 Train loss (mean): 0.0016 Train accuracy (mean): 0.9157\n",
      "Epoch: 75/150 Train loss (mean): 0.0009 Train accuracy (mean): 0.9168\n",
      "Epoch: 76/150 Train loss (mean): 0.0015 Train accuracy (mean): 0.9179\n",
      "Epoch: 77/150 Train loss (mean): 0.0007 Train accuracy (mean): 0.9190\n",
      "Epoch: 78/150 Train loss (mean): 0.0005 Train accuracy (mean): 0.9200\n",
      "Epoch: 79/150 Train loss (mean): 0.0008 Train accuracy (mean): 0.9210\n",
      "Epoch: 80/150 Train loss (mean): 0.0008 Train accuracy (mean): 0.9220\n",
      "Epoch: 81/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9230\n",
      "Epoch: 82/150 Train loss (mean): 0.0004 Train accuracy (mean): 0.9239\n",
      "Epoch: 83/150 Train loss (mean): 0.0004 Train accuracy (mean): 0.9249\n",
      "Epoch: 84/150 Train loss (mean): 0.0014 Train accuracy (mean): 0.9258\n",
      "Epoch: 85/150 Train loss (mean): 0.0005 Train accuracy (mean): 0.9266\n",
      "Epoch: 86/150 Train loss (mean): 0.0006 Train accuracy (mean): 0.9275\n",
      "Epoch: 87/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9283\n",
      "Epoch: 88/150 Train loss (mean): 0.0005 Train accuracy (mean): 0.9292\n",
      "Epoch: 89/150 Train loss (mean): 0.0005 Train accuracy (mean): 0.9300\n",
      "Epoch: 90/150 Train loss (mean): 0.0010 Train accuracy (mean): 0.9307\n",
      "Epoch: 91/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9315\n",
      "Epoch: 92/150 Train loss (mean): 0.0092 Train accuracy (mean): 0.9322\n",
      "Epoch: 93/150 Train loss (mean): 0.0062 Train accuracy (mean): 0.9329\n",
      "Epoch: 94/150 Train loss (mean): 0.0005 Train accuracy (mean): 0.9335\n",
      "Epoch: 95/150 Train loss (mean): 0.0005 Train accuracy (mean): 0.9342\n",
      "Epoch: 96/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9349\n",
      "Epoch: 97/150 Train loss (mean): 0.0007 Train accuracy (mean): 0.9356\n",
      "Epoch: 98/150 Train loss (mean): 0.0011 Train accuracy (mean): 0.9363\n",
      "Epoch: 99/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9369\n",
      "Epoch: 100/150 Train loss (mean): 0.0017 Train accuracy (mean): 0.9375\n",
      "Epoch: 101/150 Train loss (mean): 0.0005 Train accuracy (mean): 0.9382\n",
      "Epoch: 102/150 Train loss (mean): 0.0018 Train accuracy (mean): 0.9388\n",
      "Epoch: 103/150 Train loss (mean): 0.0008 Train accuracy (mean): 0.9394\n",
      "Epoch: 104/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9399\n",
      "Epoch: 105/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9405\n",
      "Epoch: 106/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9411\n",
      "Epoch: 107/150 Train loss (mean): 0.0002 Train accuracy (mean): 0.9416\n",
      "Epoch: 108/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9422\n",
      "Epoch: 109/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9427\n",
      "Epoch: 110/150 Train loss (mean): 0.0004 Train accuracy (mean): 0.9432\n",
      "Epoch: 111/150 Train loss (mean): 0.0006 Train accuracy (mean): 0.9437\n",
      "Epoch: 112/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9442\n",
      "Epoch: 113/150 Train loss (mean): 0.0010 Train accuracy (mean): 0.9447\n",
      "Epoch: 114/150 Train loss (mean): 0.0006 Train accuracy (mean): 0.9452\n",
      "Epoch: 115/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9457\n",
      "Epoch: 116/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9462\n",
      "Epoch: 117/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9466\n",
      "Epoch: 118/150 Train loss (mean): 0.0002 Train accuracy (mean): 0.9471\n",
      "Epoch: 119/150 Train loss (mean): 0.0008 Train accuracy (mean): 0.9475\n",
      "Epoch: 120/150 Train loss (mean): 0.0002 Train accuracy (mean): 0.9480\n",
      "Epoch: 121/150 Train loss (mean): 0.0005 Train accuracy (mean): 0.9484\n",
      "Epoch: 122/150 Train loss (mean): 0.0002 Train accuracy (mean): 0.9488\n",
      "Epoch: 123/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9492\n",
      "Epoch: 124/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9497\n",
      "Epoch: 125/150 Train loss (mean): 0.0006 Train accuracy (mean): 0.9501\n",
      "Epoch: 126/150 Train loss (mean): 0.0002 Train accuracy (mean): 0.9505\n",
      "Epoch: 127/150 Train loss (mean): 0.0002 Train accuracy (mean): 0.9508\n",
      "Epoch: 128/150 Train loss (mean): 0.0005 Train accuracy (mean): 0.9512\n",
      "Epoch: 129/150 Train loss (mean): 0.0002 Train accuracy (mean): 0.9516\n",
      "Epoch: 130/150 Train loss (mean): 0.0007 Train accuracy (mean): 0.9520\n",
      "Epoch: 131/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9523\n",
      "Epoch: 132/150 Train loss (mean): 0.0002 Train accuracy (mean): 0.9527\n",
      "Epoch: 133/150 Train loss (mean): 0.0004 Train accuracy (mean): 0.9531\n",
      "Epoch: 134/150 Train loss (mean): 0.0002 Train accuracy (mean): 0.9534\n",
      "Epoch: 135/150 Train loss (mean): 0.0002 Train accuracy (mean): 0.9538\n",
      "Epoch: 136/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9541\n",
      "Epoch: 137/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9544\n",
      "Epoch: 138/150 Train loss (mean): 0.0004 Train accuracy (mean): 0.9548\n",
      "Epoch: 139/150 Train loss (mean): 0.0000 Train accuracy (mean): 0.9551\n",
      "Epoch: 140/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9554\n",
      "Epoch: 141/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9557\n",
      "Epoch: 142/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9560\n",
      "Epoch: 143/150 Train loss (mean): 0.0004 Train accuracy (mean): 0.9564\n",
      "Epoch: 144/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9567\n",
      "Epoch: 145/150 Train loss (mean): 0.0003 Train accuracy (mean): 0.9570\n",
      "Epoch: 146/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9573\n",
      "Epoch: 147/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9575\n",
      "Epoch: 148/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9578\n",
      "Epoch: 149/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9581\n",
      "Epoch: 150/150 Train loss (mean): 0.0001 Train accuracy (mean): 0.9584\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "\n",
    "model = emoji_model(num_classes=num_classes, num_steps=maxLen,\n",
    "                lstm_size=lstm_size, lstm_layers=lstm_layers, learning_rate=learning_rate)\n",
    "\n",
    "saver = tf.train.Saver() \n",
    "\n",
    "train_acc_mean = []\n",
    "loss_vec = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(model.embedding_init, feed_dict={model.embedding_placeholder: model.emb_matrix})\n",
    "    \n",
    "    global_iteration = 0\n",
    "    for e in range(epochs):\n",
    "        train_acc = []\n",
    "        loss_epoch=[]\n",
    "        \n",
    "        num_iterations=int(np.ceil(len(X_train_indices)/batch_size))\n",
    "        index_last_iter=int(((len(X_train_indices)/batch_size)-(len(X_train_indices)//batch_size))*batch_size)\n",
    "        iteration=1\n",
    "        for (x, y) in get_batches(X_train_indices, Y_train, batch_size):\n",
    "                   \n",
    "            if (iteration==1):\n",
    "                feed = {model.inputs_: x}\n",
    "                state = sess.run(model.initial_state,feed_dict=feed)\n",
    "                \n",
    "                feed = {model.inputs_: x,\n",
    "                   model.labels_: y[:, None],\n",
    "                   model.keep_prob: 0.5,\n",
    "                   model.initial_state: state}\n",
    "              \n",
    "            elif (iteration==num_iterations): # We include the last batch that is not complete\n",
    "                new_state=()\n",
    "                for lstm_layers_index in range(0, lstm_layers):\n",
    "                    c=state[lstm_layers_index][0][0:index_last_iter]\n",
    "                    h=state[lstm_layers_index][1][0:index_last_iter]\n",
    "                    ch = tf.contrib.rnn.LSTMStateTuple(c, h)  \n",
    "                    new_state=new_state+(ch,)\n",
    "                    #new_state=new_state+ch # I think this is wrong, but seems to work too\n",
    "                    \n",
    "                feed = {model.inputs_: x,\n",
    "                   model.labels_: y[:, None],\n",
    "                   model.keep_prob: 0.5,\n",
    "                   model.initial_state: new_state}\n",
    "    \n",
    "            else:\n",
    "                feed = {model.inputs_: x,\n",
    "                   model.labels_: y[:, None],\n",
    "                   model.keep_prob: 0.5,\n",
    "                   model.initial_state: state}\n",
    "                   \n",
    "\n",
    "            batch_acc,batch_acc_op,batch_loss, state,_= sess.run([model.acc, model.acc_op,\n",
    "                                                                    model.loss, model.final_state,\n",
    "                                                                    model.optimizer],\n",
    "                                                                    feed_dict=feed)\n",
    "\n",
    "            train_acc.append(batch_acc_op)\n",
    "            loss_epoch.append(batch_loss)\n",
    "            loss_vec.append(batch_loss)\n",
    "            \n",
    "            iteration +=1\n",
    "            global_iteration +=1\n",
    "        \n",
    "        if (e%1==0):\n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                     \"Train loss (mean): {:.4f}\".format(np.mean(loss_epoch)),\n",
    "                      \"Train accuracy (mean): {:.4f}\".format(np.mean(train_acc)))\n",
    "        \n",
    "        train_acc_mean.append(np.mean(train_acc))\n",
    "    saver.save(sess, \"checkpoints/emojify.ckpt\")                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Plot training loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6oAAAF3CAYAAACsQ7bGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12bd2a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(1,global_iteration+1), loss_vec)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(1,epochs+1), train_acc_mean)\n",
    "plt.ylabel('mean accuracy per epoch')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 Test loss: 1.659 Test accuracy: 0.8750\n",
      "Iteration: 2 Test loss: 2.147 Test accuracy: 0.7857\n",
      "Test accuracy (mean): 0.830\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = []\n",
    "test_predictions_val=[]\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    num_iterations=int(np.ceil(len(X_test_indices)/batch_size))\n",
    "    index_last_iter=int(((len(X_test_indices)/batch_size)-(len(X_test_indices)//batch_size))*batch_size)\n",
    "    \n",
    "    iteration=1\n",
    "    for (x, y) in get_batches(X_test_indices, Y_test, batch_size):\n",
    "                   \n",
    "        if (iteration==1):\n",
    "            feed = {model.inputs_: x}\n",
    "            test_state = sess.run(model.cell.zero_state(tf.shape(x)[0], tf.float32))    \n",
    "                \n",
    "            feed = {model.inputs_: x,\n",
    "                   model.labels_: y[:, None],\n",
    "                   model.keep_prob: 1,\n",
    "                   model.initial_state: test_state}\n",
    "              \n",
    "        elif (iteration==num_iterations):\n",
    "            new_state=()\n",
    "            for lstm_layers_index in range(0, lstm_layers):\n",
    "                c=test_state[lstm_layers_index][0][0:index_last_iter]\n",
    "                h=test_state[lstm_layers_index][1][0:index_last_iter]\n",
    "                ch = tf.contrib.rnn.LSTMStateTuple(c, h)  \n",
    "                new_state=new_state+(ch,)\n",
    "                \n",
    "                    \n",
    "            feed = {model.inputs_: x,\n",
    "                   model.labels_: y[:, None],\n",
    "                   model.keep_prob: 1,\n",
    "                   model.initial_state: new_state}\n",
    "    \n",
    "        else:\n",
    "            feed = {model.inputs_: x,\n",
    "                   model.labels_: y[:, None],\n",
    "                   model.keep_prob: 1,\n",
    "                   model.initial_state: test_state}\n",
    "            \n",
    "        test_predictions,test_loss, test_batch_acc,test_batch_acc_op, test_state = sess.run([model.predictions, \n",
    "                                                                                             model.loss,\n",
    "                                                                                   model.acc,model.acc_op, \n",
    "                                                                                   model.final_state], \n",
    "                                                                feed_dict=feed)\n",
    "        test_accuracy.append(test_batch_acc_op) \n",
    "        test_predictions_val.extend(np.argmax(test_predictions,1))\n",
    "        \n",
    "        print(\"Iteration: {}\".format(iteration),\n",
    "                      \"Test loss: {:.3f}\".format(test_loss),\n",
    "                      \"Test accuracy: {:.4f}\".format(test_batch_acc_op)\n",
    "                     )\n",
    "        iteration +=1\n",
    "        \n",
    "    print(\"Test accuracy (mean): {:.3f}\".format(np.mean(test_accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected and predicted emoji of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected emoji:ðŸ´ prediction: I want to eat\tðŸ´\n",
      "Expected emoji:ðŸ˜ž prediction: he did not answer\tðŸ˜ž\n",
      "Expected emoji:ðŸ˜„ prediction: he got a very nice raise\tðŸ˜„\n",
      "Expected emoji:ðŸ˜„ prediction: she got me a nice present\tðŸ˜„\n",
      "Expected emoji:ðŸ˜„ prediction: ha ha ha it was so funny\tðŸ˜„\n",
      "Expected emoji:ðŸ˜„ prediction: he is a good friend\tðŸ˜„\n",
      "Expected emoji:ðŸ˜ž prediction: I am upset\tðŸ˜ž\n",
      "Expected emoji:ðŸ˜„ prediction: We had such a lovely dinner tonight\tðŸ˜„\n",
      "Expected emoji:ðŸ´ prediction: where is the food\tðŸ´\n",
      "Expected emoji:ðŸ˜„ prediction: Stop making this joke ha ha ha\tðŸ˜„\n",
      "Expected emoji:âš¾ prediction: where is the ball\tâš¾\n",
      "Expected emoji:ðŸ˜ž prediction: work is hard\tðŸ˜ž\n",
      "Expected emoji:ðŸ˜ž prediction: This girl is messing with me\tðŸ˜ž\n",
      "Expected emoji:ðŸ˜ž prediction: are you seriousðŸ˜ž\n",
      "Expected emoji:âš¾ prediction: Let us go play baseball\tâš¾\n",
      "Expected emoji:ðŸ˜ž prediction: This stupid grader is not working \tðŸ˜ž\n",
      "Expected emoji:ðŸ˜ž prediction: work is horrible\tðŸ˜ž\n",
      "Expected emoji:ðŸ˜„ prediction: Congratulation for having a baby\tâ¤ï¸\n",
      "Expected emoji:ðŸ˜ž prediction: stop pissing me offðŸ˜ž\n",
      "Expected emoji:ðŸ´ prediction: any suggestions for dinner\tðŸ´\n",
      "Expected emoji:â¤ï¸ prediction: I love taking breaks\tâ¤ï¸\n",
      "Expected emoji:ðŸ˜„ prediction: you brighten my day\tâ¤ï¸\n",
      "Expected emoji:ðŸ´ prediction: I boiled rice\tðŸ´\n",
      "Expected emoji:ðŸ˜ž prediction: she is a bully\tâ¤ï¸\n",
      "Expected emoji:ðŸ˜ž prediction: Why are you feeling bad\tðŸ˜ž\n",
      "Expected emoji:ðŸ˜ž prediction: I am upset\tðŸ˜ž\n",
      "Expected emoji:âš¾ prediction: give me the ballâš¾\n",
      "Expected emoji:â¤ï¸ prediction: My grandmother is the love of my life\tðŸ˜„\n",
      "Expected emoji:âš¾ prediction: enjoy your gameâš¾\n",
      "Expected emoji:ðŸ˜„ prediction: valentine day is near\tðŸ˜„\n",
      "Expected emoji:â¤ï¸ prediction: I miss you so much\tâ¤ï¸\n",
      "Expected emoji:âš¾ prediction: throw the ball\tâš¾\n",
      "Expected emoji:ðŸ˜ž prediction: My life is so boring\tðŸ˜ž\n",
      "Expected emoji:ðŸ˜„ prediction: she said yes\tðŸ˜„\n",
      "Expected emoji:ðŸ˜„ prediction: will you be my valentine\tðŸ´\n",
      "Expected emoji:âš¾ prediction: he can pitch really well\tâ¤ï¸\n",
      "Expected emoji:ðŸ˜„ prediction: dance with me\tðŸ˜ž\n",
      "Expected emoji:ðŸ´ prediction: I am hungryðŸ´\n",
      "Expected emoji:ðŸ´ prediction: See you at the restaurant\tðŸ´\n",
      "Expected emoji:ðŸ˜„ prediction: I like to laugh\tðŸ˜„\n",
      "Expected emoji:âš¾ prediction: I will  runðŸ˜„\n",
      "Expected emoji:â¤ï¸ prediction: I like your jacket \tâ¤ï¸\n",
      "Expected emoji:â¤ï¸ prediction: i miss her\tâ¤ï¸\n",
      "Expected emoji:âš¾ prediction: what is your favorite baseball game\tâš¾\n",
      "Expected emoji:ðŸ˜„ prediction: Good job\tðŸ˜„\n",
      "Expected emoji:â¤ï¸ prediction: I love you to the stars and back\tðŸ˜„\n",
      "Expected emoji:ðŸ˜„ prediction: What you did was awesome\tðŸ˜„\n",
      "Expected emoji:ðŸ˜„ prediction: ha ha ha lol\tðŸ˜„\n",
      "Expected emoji:ðŸ˜ž prediction: I do not want to joke\tðŸ˜„\n",
      "Expected emoji:ðŸ˜ž prediction: go away\tðŸ˜ž\n",
      "Expected emoji:ðŸ˜ž prediction: yesterday we lost again\tðŸ˜„\n",
      "Expected emoji:â¤ï¸ prediction: family is all I have\tðŸ˜ž\n",
      "Expected emoji:ðŸ˜ž prediction: you are failing this exercise\tðŸ˜ž\n",
      "Expected emoji:ðŸ˜„ prediction: Good joke\tðŸ˜„\n",
      "Expected emoji:ðŸ˜„ prediction: You deserve this nice prize\tðŸ˜„\n",
      "Expected emoji:ðŸ´ prediction: I did not have breakfast ðŸ´\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_test)):\n",
    "    print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] \n",
    "          + label_to_emoji(test_predictions_val[i]).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "RNnEs",
   "launcher_item_id": "acNYU"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
